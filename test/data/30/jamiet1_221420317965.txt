
Time series 분석에 사용되는 히든 마르코프 모델! 1. Discrete Markov Processes확률을 이용하여 어떤 객체의 상태를 시간에 따라 어떻게 변화할지 모델링 하는 것이다.
날씨 예측을 예로 들어보겠다.
어떤 객체(날씨)의 상태(맑음, 흐림, 비옴)가 시간이 지남에 따라 어떻게 변할지 확률을 이용하여 예측하는 것이다.
Process 라는 단어에서 볼 수 있듯, 객체의 시간에 따른 각각 다른 상태를 어떻게 연결할지 표현하는 것이다.

어떤 시간에 대해 객체는 N개의 상태로 표현될 수 있다.
S = {S1, S2, ... , Sn}

특정 시간마다, 객체의 상태가 변한다. (상태 전이). 
상태 전이는 확률로 표현될 수 있다.

Qt= Sj
t라는 시간시점의 상태이다.

마르코프 프로세스는 미래(n+1)의 상태가 현재(n)에만 의존하고 그 이전(n-1, n-2, ...)에는 영향을 받지 않는다는 것을 가정한다.
날씨 예를 들면, 내일의 날씨는 오늘 날씨에만 상관있지 어제 날씨는 상관 없다고 하는 것이다.간단하게, 현 장태 t는 바로 이전 t-1만 상관있지, t-2, t-3... 등등 이전의 상태와는 영향이 없다고 해석하면 된다.
그리고, 두 상태간의 전이 확률은 각 상태의 시간에는 독립적이다.

a_ij : Si에서 Sj로 전이할 확률
N개 상태의 전이확률을 모두 더하면 1이다.

- 위와같이 상태 전이를 마르코프 행렬 형태로 표현할 수 있다. 이떄의 특징을 보면,
1) 모든 원소의 값이 0보다 크거나 같다. 상태 전이 확률을 나타내기 때문에 음수가 있을 수 없다. 
시간이 지남에 따라 변화하는 상태를 예측하기 위한 행렬이므로, 행렬의 거듭제곱이 발생하는데, 당연히 이 결과값도 양수다.

2) 각 column의 원소합은 1이다. 하나의 column은 어떤 상태에 대한 모든 전이 확률을 나타내기 때문이다.


2. Hidden Markov models (HMM)바로 전에는 관측된 값들만 가능했는데,  모든 상태가 관측되는... 그런 경우는 실제로 잘 없을 것이다.
HMM은 현재의 상태가 숨겨져 있다고 가정하고, 보여지는 정보를 통해 현재의 상태를 도출하는 것이다.

관찰 가능한 결과를 야기하는 직접적인 원인은 관측될 수 없는 숨겨진 상태들이고, 마르코프 과정을 통해 도출된 결과가 관찰될 수 있기 때문에 Hidden이 붙었다.
상태를 직접적으로 볼 수 없고 상태들로부터 야기된 결과들만을 관찰할 수 있다. 각각의 상태는 특정 확률 분포에 따라 여러가지 결과를 도출해 낼 수 있으므로, HMM으로부터 생성된 결과들의 나열은 숨겨진상태들에 대한 정보들을 제공하고 있다고 생각할 수 있다.
 숨겨진 상태는 모델의 파라미터를 가리키는 것이 아니라 모델이 거쳐가는 연속된 상태를 지칭하는 것에 주의하자.  파라미터들은 알려져있지만 결과를 야기하는 상태들이 근본적으로 숨겨져있어서 관찰할수 없기 때문이다.


2-1. 예시들
동전던지기를 예로 들어보자.
커튼이 있는 방에 있는데, 커튼 뒤에서 동전 던지기를 하는 사람이 있다.
이 사람은 동전을 몇 개 선택해서 던진 후 (H, T) 결과를 알려 줄 것이다.  앞면은 H, 뒷면은 T.
하지만 어떤 동전을 던졌는지는 알려주지 않을 것이다.

이 때 각 동전들이 앞면인지 뒷 면인지를 예측해보는 모델을 구축한다.
O = {o1, o2,o3 , ... } = {H, T, T, H, ... }

매 번 어떤 동전이 던져진진 알 수 없고, 이 때 HMM은 얼마나 많은 상태를 가져야할까?

1) 1-coin 모델
커튼 뒤 사람이 동전을 한 개만 가지고 이다고 가정해보자.
상태가 1개 뿐이니까 마르코프모델은 관찰가능하다.
각 경우, 모델 파라미터 P(H)는 그냥 앞면/뒷면이 나오는 비율이다.
2) 2-coin 모델
자, 좀 더 복잡해진다.
각 동전은 H냐 T냐의 분포를 가진다.
두 상태간의 전이는 random process다.
모델은 4개의 파라미터를 가진다.


3) 3-coin 모델
모델이 3개의 분리된 상태를 가진다. (뭐 2-coin과 비슷하긴 하다)
모델은 9개의 파라미터를 가진다.

- 어떤 모델이 best일까?
각 상태를 알 수 없으니까, 최선은 데이터를 가장 잘 설명하는 모델을 고르는 것이다.
( 최대 우도 기준을 쓴다던가 하는 방식으로 )


그릇의 공 문제 예시도 있다.
또 커튼이 있는 방에 있다. 커튼 뒤에 N 개의 그릇이 있고, 각 그릇에는 M개의 각 다른 색을 가진 여러개의 공이 들어있다.
커튼 뒤의 사람이 내부 random process에 따라 공을 선택한 후 공을 보여준다.
이 과정이 계속 될 것이다.

음.. 이걸 HMM 으로 어떻게 표현해볼까?
N개 그릇에서 공의 개수가 다 다르다 == 각 그릇에서의 출력 확률이 다 다르다.
그릇이 N개다 == 상태의 수가 N개다
색깔이 3 종류이다 == 3가지 관측 벡터가 나온다.

2-2. HMM elements
- N : 모델 S의 상태 수. S = {S1, S2, ... , Sn}
- M : 관측 벡터 수. V = { V1, V2, ... , Vm }
   어떤 인뎃스와 가까운지 설정해서 관측 v 결정한다.
- A = { Aij } 상태 전이 확률

- B = { Bj(k) } 관측 확률 분포. 같은 시점에서 Vk 라는 관측벡터가 출력될 확률

- 파이, 분포의 초기 상태

즉, HMM은 두 스칼라(N, M)과 세개의 확률 분포 (A, B, 파이)로 표현된다.

예시들에서도 봤지만 관찰자는 각 상태에서 뽑혀나온 y1, ~y4만 알 수 있다.
그릇 안의 내부 공들의 비율을 알고, y1, y2, y3의 공들을 관측했어도 여전히 3번째 공을 뽑은 그릇의 상태 x는 알 수 없다. 다만 y3가 각 그릇에서 뽑혔을 우도(likelihood)같은 정보들에 대해 계산을 할 수 있을 뿐이다.

2-3. HMM은 관측 시퀀스를 만들어준다.
λ = (A, B, π) 가 있을 때, 어떻게 관측 상태 시퀀스 O = {O1, O2, ..., On}을 만들까?
1) 초기 분포 π를 고려하여 초기 상태 S1을 선택한다.
2) t = 1 로 세팅
3) emission 확률 Bj(k)를 보고 Ot 관측상태를 만든다.
4) 상태 전이 Aij에 따라 새 상태 St+1로 옮긴다
5) t = t + 1로 세팅하고, t &gt;= T 될때 까지 3)을 반복한다.

2-4. HMM의 문제
자 이제 실제로 어떤 문제들을 풀어야할까?

1) 확률 계산
관측 상태 시퀀스 O = {O1, O2, ..., On} 와 모델 λ= (A, B, π) 이 주어졌을 때
P(O|λ)를 계산하는 방법은?
-&gt; forward, backward procedure를 이용한다.

2) 최적 상태 추론
관측 상태 시퀀스 O = {O1, O2, ..., On} 와 모델 λ= (A, B, π) 이 주어졌을 때
데이터를 가장 잘 설명할 쵲거의 상태 시퀀스 Q = {Q1, Q2, Q3 ... }을 선택하는 방법은?
사실 진짜 알고 싶은 건 이거다.
즉, 가장 확률이 높은 상태의 순열을 찾는 방법은?
-&gt; Viterbi 알고리즘을 사용한다.

3) 파라미터 추정
학습에 관련된 이슈다. 학습 데이터를 가지고 있는 상태에서 학습 알고리즘을 통해 '람다'를 최적화 해야 한다.
P(O|λ)를 최대화 하는 모델 λ= (A, B, π)의 파라미터는 어떻게 조절하나?
즉, 동전 던지기에서 처럼 초기확률, 추정상태, 전이확률, 출력확률 등을 알 수 없는데 이걸 어떻게 추정하지?
-&gt; Baum-Welch re-estimation procedure (재추정 알고리즘) 를 이용한다.



3. Forward and Backward procedures문제 1)인 확률 계산에 대한 해결책이다.
HMM 모델 λ= (A, B, π)을 통해 상태 시퀀스의 가능도(likelihood)를 계산하는 게 목표다.
모든 상태 시퀀스 Q에 대해 대해 1~p 까지의 시계열의 관측 데이터에 대한 우도를 구한다.



예를 들어, 관측 데이터가 x1 ~ x8일 때 그에 대응하는 상태 시퀀스 Q는 엄청나게 많을 것이다.



하지만 확률로 표현하면 전부 or이니까 다 더하면 된다.
시그마 안에 들어가있는 수식은 조건부 확률을 베이지안에 의해 뒤집은 결과이다.
이 수식을 어떻게 계산할까? 


하나의 Q = q1 ~ qT에 대해서만 생각해 보면,

모든 Q에 대해 합하면

Aij : i에서 j로 전이할 확률
Bi(Oi) : i상태에서 관측값 Oi를 얻을 확률
N^t개 경우의 수 가 있으므로
( N : 상태수, t : 시퀀스 수, 각 시간 t의 수 )
t개의 시간 시점에 2개의 데이터가 곱해진다.
N^t X 2t =&gt; 전체계산량이 되어 계산량이 너무 많다.

다행히 이것도 Markov Model처럼 DP 기법(수학적 귀납법을 생각)을 사용하면, 빠르게 계산할 수 있다.  알고리즘으로 해결하자!

모든 관측 t시점이 N개의 상태를 가진다.시간이 지나갈 때 상태를 보니 격자형이다. 즉, 시간 t 에서의 확률은  시간 t-1 에서의 확률을 알면,  t-1 에서 t 까지의 모든 path만 고려해면 된다. 이걸 이용해서 계산량을 줄일 수 있다. 시퀀스별로 따로 계산하지 말고, 바로 앞의 계산을 이용하는 것이다.

 3-1. Forward Algorithm
Forward : 계산 순서가 1부터 t까지 순차적으로 계산하기 때문에 붙여졌다.

At(i)가 t 시점에 상태 i일 확률이라고 하자. HMM이 필요하다. t-1, t-2 이점은 관심사가 아니다. 다훑고 지나온 애들일 뿐이다. 

1) initialization
    - 첫번 째 관측 데이터인 초기값을 설정한다.2) induction (귀납법)
    a(t)과 a(t+1)의 관계를 수식으로 표현한다.

  그래서 귀납법(induction)이다. ==  그래서 연역법(deduction)이 아니다.

3. termination
계산하려고 하는 대상이 a(T)인 경우, a(T+1)은 계산할 필요가 없다. 그래서 종료 조건이 반드시 필요하다.
- 결과적으로 P(O|λ)의 계산량이 2T x T^N 에서 N^2 x T로 확 줄어든다. 3-2. Backward Algorithm
종점부터 시작해서 거꾸로 내려오는 방법이다.


t +1 에서 끝까지 간다.

1) initialization

2) Induction

임의의 t시점에서 Aij의 전이확률을 가진다.
i가 이전의 t시점이고, j는 t+1시점이다.
backward방향으로 똑같이 계산한다.


다만, 초기 상태까지 와 봐야, 그 중간에 저장된 확률 값들을 알 수 있다는 단점이 있다.


forward, backward 알고리즘을 통해 어떤 결과 시퀀스가 주어져도 그 확률을 계산할 수 있다.

4. The Viterbi algorithm첫 번째 문제는 Forward Backward 알고리즘으로 해결했고, 두 번째 문제로 넘어가자.
관측된 결과 시퀀스로부터 가장 가능성이 큰 상태시퀀스를 구하는 문제다.

이를 해결하기 위해 두 가지가 가능하다.
1) 각 시간 t만 고려하여, t 시점에서 가장 그럴듯한 상태 Qt 구하기 (individual)
2) 가장 있을법한 상태 시퀀스의 path를 구하기 - Viterbi 알고리즘 -  이걸 더 많이 쓴다.

하지만, 1)번의 방법이 결국 파라미터 추정하는 데 사용되니까 먼저보자

전체 시점에서 t시점에 i번째에 이을 확률을 구한다.
Si : t시점에 i에 있을 확률

조건부 확률을 이용하면,

분자인 Rt(i)는 At(i), Bt(i)의 곱과 같다.

각 시간에서 가장 가능성이 큰 Qt에 있을 가능성은

하지만, 문제가 있다. 오직 t 시점만 본다는 것이다.
고로 t 시점에 가장 확률이 큰 상태로만 선정하면, 그 다음시간의  상태로 연결이 안될 수 있다.
Qt = i, Qt+1 = j 인데
Aij = 0 일 수가 있는거다.

그래서 상태 시퀀스 자체를 최적화 해주는 차선책을 고려하는 것이다.

4-1. Viterbi 알고리즘
single best 상태 시퀀스를 보자.
most probable  sequence decoding이라고도 한다.

Q = q1, q2, ... qt의 상태시퀀스(path)가 있고, t번째 상태가 i가 될 확률이다.
단일 path를 따라 첫 t의 상태가 i가 되는 확률을 최대로 하는 상태 시퀀스 Q를 찾는다.
즉, path의 확률을 계산한다.
t 시점에서 가능한 여러개의 상태에서 t+1의 어떤 상태 q(j)로 오는 path는, t 시점의 상태의 숫자만큼 존재한다. 그럼... path의 관점에서, 어떤 path로 오는 것이 가장 그럴듯 한지를 생각해줘야한다.
이 때 두가지를 고려해준다. 
1) Aij : t 시점의 i 상태에서 t+1의 상태 q(j)로의 전이 확률
2) Bj(Ot+1) : q(j)에서 관측된 output o(t+1)의 확률

귀납법(induction)으로 계산하면, 이 두가지 확률을 곱한 값이 최대가 되는 path(Q1~Qt-1)를 선택한다.

상태 시퀀스를 찾기 위해, 각 시간 t에서 path 확률을 최대화 하는 path node를 구해야한다. 직전 과거가 어딨는지를 알기위해서다. 
즉, path 확률에서 목적지의 output 확률을 제거하고, 그 확률이 최대가 되는 이전 상태이다. 현재 output이 어딨는지 고려하지 않고 계산한다.

- path node : 5 입장에서 직전 상태

그리고, 최적 상태 시퀀스는 backtracking으로 구한다.

viterbi 알고리즘은 global search이다.
앞서 말한 각각 상태에서 최선의 확률을 구한 게 local search 였는데, 이 한계를 벗어나기 위해 고안된 알고리즘이 아닌가.
그런데, global search는 가능한 path를 전부 계산하기 때문에 시간이 오래 걸린다. 
( local search는 그냥 단순하게 현재만 보고 가장 최선을 찾는 놈이므로  greedy search라고도 한다. )
viterbi 알고리즘은 가장 최적의 path를 선택해야 하기 때문에 끝까지 가본 이후,
마지막 상태부터 거꾸로 backtracking을 하면서 가장 확률이 높게 나오는 이전 상태를 선택해 가면서 처음 상태로 되돌아 가야 최종적인 결과가 나오는 알고리즘이다.

 자 이젠 output 시퀀스를 알면 대응되는 상태 시퀀스를 계산할 수 있다.




참고 출처
수업
https://ko.wikipedia.org/wiki/%EC%9D%80%EB%8B%89_%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84_%EB%AA%A8%EB%8D%B8(위키백과) 
https://blog.naver.com/koys007/221363053904 (koys007 블로그)
https://twlab.tistory.com/53 (러너개인 블로그)


